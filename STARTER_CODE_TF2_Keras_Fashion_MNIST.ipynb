{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ddaci/RNP_5/blob/main/STARTER_CODE_TF2_Keras_Fashion_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2NPAI4jZZgi"
      },
      "source": [
        "# Classify Fashion-MNIST with CNN in Keras using TensorFlow 2.0\n",
        "\n",
        "**@Catalin Caleanu, 2019**\n",
        "\n",
        "Adapted from:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwTrRxmoemWe"
      },
      "source": [
        "**Margaret Maynard-Reid**\n",
        "![alt text](https://github.com/margaretmz/deep-learning/blob/master/images/modern%20dl_fash-mnist_keras.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIqCJe_xcOU5"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J76ctP9PT-9N"
      },
      "outputs": [],
      "source": [
        " ## YOUR CODE HERE ##\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ixyte299ZZgk"
      },
      "source": [
        "## The Dataset\n",
        "\n",
        "Why Fashion-MNIST?\n",
        "\n",
        "*   MNIST is too easy\n",
        "*   MNIST is overused\n",
        "*   MNIST can not represent modern Computer Vision tasks\n",
        "\n",
        "Read more about the Fashion-MINST dataset in this paper [here](https://arxiv.org/abs/1708.07747) (**Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms**)\n",
        "\n",
        "The [fashion_mnist](https://github.com/zalandoresearch/fashion-mnist) data:\n",
        "60,000 train and 10,000 test data with 10 categories. Each gray-scale image is 28x28.\n",
        "\n",
        "**Label**\t**Description**\n",
        "<br> 0 T-shirt/top\n",
        "<br> 1 Trouser\n",
        "<br> 2 Pullover\n",
        "<br> 3 Dress\n",
        "<br> 4 Coat\n",
        "<br> 5 Sandal\n",
        "<br> 6 Shirt\n",
        "<br> 7 Sneaker\n",
        "<br> 8 Bag\n",
        "<br> 9 Ankle boot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wa0HE1nXcT7Q"
      },
      "source": [
        "## Loading data and visualisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d44TznbgZZgm"
      },
      "outputs": [],
      "source": [
        " ## YOUR CODE HERE ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aFe4wHGRFKle"
      },
      "outputs": [],
      "source": [
        "# Define the text labels\n",
        "fashion_mnist_labels = [\"T-shirt/top\",  # index 0\n",
        "                        \"Trouser\",      # index 1\n",
        "                        \"Pullover\",     # index 2\n",
        "                        \"Dress\",        # index 3\n",
        "                        \"Coat\",         # index 4\n",
        "                        \"Sandal\",       # index 5\n",
        "                        \"Shirt\",        # index 6\n",
        "                        \"Sneaker\",      # index 7\n",
        "                        \"Bag\",          # index 8\n",
        "                        \"Ankle boot\"]   # index 9\n",
        "\n",
        "# Show first 25 images from the training dataset\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5, 5, i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.imshow(train_images[i], cmap=plt.cm.brg)\n",
        "    plt.xlabel(fashion_mnist_labels[train_labels[i]])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zx-Ee6LHZZgt"
      },
      "source": [
        "## Data normalization\n",
        "Normalize the data dimensions so that they are of the same scale. Scale these values to a range of 0 to 1 before feeding them to the neural network model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fro5wEeqltYG"
      },
      "outputs": [],
      "source": [
        "# Reshape input data from (28, 28) to (28, 28, 1) as\n",
        "# mnist.load_data() supplies the MNIST digits with structure (nb_samples, 28, 28)\n",
        "# The Convolution2D layers in Keras however, are designed to work with 3 dimensions per example\n",
        "# They have 4-dimensional inputs and outputs. This covers colour images (nb_samples, nb_channels, width, height)\n",
        "\n",
        " ## YOUR CODE HERE ##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFlNHktHBtru"
      },
      "source": [
        "## Split the data into train/validation/test data sets\n",
        "\n",
        "\n",
        "*   Training data - used for training the model\n",
        "*   Validation data - used for tuning the hyperparameters and evaluate the models\n",
        "*   Test data - used to test the model after the model has gone through initial vetting by the validation set.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ShU787gZZg0"
      },
      "outputs": [],
      "source": [
        "# Further break training data into train / validation sets\n",
        "# put 5000 into validation set and keep remaining 55,000 for train)\n",
        "\n",
        " ## YOUR CODE HERE ##\n",
        "\n",
        "# Print training set shape\n",
        "print(\"train_images shape:\", train_images.shape, \"train_labels shape:\", train_labels.shape)\n",
        "\n",
        "# Print the number of training, validation, and test datasets\n",
        "print(train_images.shape[0], 'train set')\n",
        "print(x_valid.shape[0], 'validation set')\n",
        "print(test_images.shape[0], 'test set')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhalcO03ZZg3"
      },
      "source": [
        "## Model Definition\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QgTZ47SsZZg4"
      },
      "outputs": [],
      "source": [
        "IMG_SIZE = (28, 28, 1)\n",
        "\n",
        "# Sequential model with the following paramaters:\n",
        "\n",
        "#Conv2D(filters=64, kernel_size=(2,2), padding='same', activation='relu', input_shape=IMG_SIZE))\n",
        "#MaxPooling2D(pool_size=(2, 2)))\n",
        "#Dropout(0.3))\n",
        "\n",
        "#Conv2D(filters=32, kernel_size=(2,2), padding='same', activation='relu'))\n",
        "#MaxPooling2D(pool_size=(2, 2)))\n",
        "#Dropout(0.3))\n",
        "\n",
        "#Flatten())\n",
        "#Dense(256, activation='relu'))\n",
        "#Dropout(0.5))\n",
        "#Dense(10, activation='softmax'))\n",
        "\n",
        "# Take a look at the model summary\n",
        "\n",
        " ## YOUR CODE HERE ##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhxJ5dinZZg8"
      },
      "source": [
        "## Compile the model\n",
        "Configure the learning process with compile() API before training the model. It receives three arguments:\n",
        "\n",
        "*   An optimizer\n",
        "*   A loss function\n",
        "*   A list of metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CQUlOa8cZZg9"
      },
      "outputs": [],
      "source": [
        " ## YOUR CODE HERE ##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtOvh3YVZZg_"
      },
      "source": [
        "## Train the model\n",
        "\n",
        "Now let's train the model with fit() API.\n",
        "\n",
        "We use  the [ModelCheckpoint](https://keras.io/callbacks/#modelcheckpoint) API to save the model after every epoch. Set \"save_best_only = True\" to save only when the validation accuracy improves.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZTmapAttZZhA"
      },
      "outputs": [],
      "source": [
        "history = model.fit(train_images,\n",
        "         train_labels,\n",
        "         batch_size=64,\n",
        "         epochs=3,\n",
        "         validation_data=(x_valid, y_valid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JNTjhoAUquEW"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0.7, 1])\n",
        "plt.legend(loc='best')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "64Z2Tjb8u5Xg"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['loss'], label='loss')\n",
        "plt.plot(history.history['val_loss'], label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(loc='best')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RTRkan4yq5H"
      },
      "source": [
        "## Test Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZtqBqFFy62R"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model on test set\n",
        " ## YOUR CODE HERE ##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJv7XEk10bOv"
      },
      "source": [
        "## Visualize prediction\n",
        "Now let's visualize the prediction using the model you just trained.\n",
        "First we get the predictions with the model from the test data.\n",
        "Then we print out 15 images from the test data set, and set the titles with the prediction (and the groud truth label).\n",
        "If the prediction matches the true label, the title will be green; otherwise it's displayed in red."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QwNmlfIC0YxM"
      },
      "outputs": [],
      "source": [
        "y_hat = model.predict(test_images)\n",
        "\n",
        "# Plot a random sample of 10 test images, their predicted labels and ground truth\n",
        "figure = plt.figure(figsize=(20, 8))\n",
        "for i, index in enumerate(np.random.choice(test_images.shape[0], size=15, replace=False)):\n",
        "    ax = figure.add_subplot(3, 5, i + 1, xticks=[], yticks=[])\n",
        "    # Display each image\n",
        "    ax.imshow(np.squeeze(test_images[index]))\n",
        "    predict_index = np.argmax(y_hat[index])\n",
        "    true_index = np.argmax(test_labels[index])\n",
        "    # Set the title for each image\n",
        "    ax.set_title(\"{} ({})\".format(fashion_mnist_labels[predict_index],\n",
        "                                  fashion_mnist_labels[true_index]),\n",
        "                                  color=(\"green\" if predict_index == true_index else \"red\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8AehWdRAVKN5"
      },
      "source": [
        "## Congragulations!\n",
        "You have successfully trained a CNN to classify fashion-MNIST."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}